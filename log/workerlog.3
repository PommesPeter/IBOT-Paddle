/home/xiejunlin/miniconda3/envs/torch/bin/python: can't open file 'train.py': [Errno 2] No such file or directory
Traceback (most recent call last):
  File "main_ibot.py", line 29, in <module>
    import models
  File "/home/xiejunlin/workspace/IBOT-Paddle/models/__init__.py", line 3, in <module>
    from ibot import IBOT_ViT_small_patch16_224
ModuleNotFoundError: No module named 'ibot'
Traceback (most recent call last):
  File "main_ibot.py", line 29, in <module>
    import models
  File "/home/xiejunlin/workspace/IBOT-Paddle/models/__init__.py", line 3, in <module>
    from .ibot import IBOT_ViT_small_patch16_224
  File "/home/xiejunlin/workspace/IBOT-Paddle/models/ibot.py", line 23, in <module>
    from .utils import (load_dygraph_pretrain,
  File "/home/xiejunlin/workspace/IBOT-Paddle/models/utils.py", line 21, in <module>
    from .download import get_weights_path_from_url
  File "/home/xiejunlin/workspace/IBOT-Paddle/models/download.py", line 31, in <module>
    from . import logger
ImportError: cannot import name 'logger' from partially initialized module 'models' (most likely due to a circular import) (/home/xiejunlin/workspace/IBOT-Paddle/models/__init__.py)
Traceback (most recent call last):
  File "main_ibot.py", line 30, in <module>
    import utils
  File "/home/xiejunlin/workspace/IBOT-Paddle/utils.py", line 526, in <module>
    class LARS(paddle.optimizer.Optimizer):
  File "/home/xiejunlin/workspace/IBOT-Paddle/utils.py", line 537, in LARS
    @torch.no_grad()
NameError: name 'torch' is not defined
I0405 08:13:37.079604 2400186 tcp_utils.cc:130] Successfully connected to 127.0.1.1:53014
Traceback (most recent call last):
  File "main_ibot.py", line 475, in <module>
    train_ibot(args)
  File "main_ibot.py", line 160, in train_ibot
    dist.init_parallel_env()
  File "/home/xiejunlin/miniconda3/envs/torch/lib/python3.8/site-packages/paddle/distributed/parallel.py", line 297, in init_parallel_env
    paddle.distributed.barrier(group=group)
  File "/home/xiejunlin/miniconda3/envs/torch/lib/python3.8/site-packages/paddle/distributed/collective.py", line 280, in barrier
    task = group.process_group.barrier()
ValueError: (InvalidArgument) TCP send error. Details: Broken pipe.
  [Hint: Expected byte_sent > 0, but received byte_sent:-1 <= 0:0.] (at /paddle/paddle/fluid/distributed/store/tcp_utils.h:86)

I0405 08:31:50.066102 2488335 tcp_utils.cc:107] Retry to connect to 127.0.1.1:54371 while the server is not yet listening.
I0405 08:31:53.066504 2488335 tcp_utils.cc:130] Successfully connected to 127.0.1.1:54371
W0405 08:31:56.561077 2488335 gpu_resources.cc:61] Please NOTE: device: 7, GPU Compute Capability: 8.6, Driver API Version: 11.5, Runtime API Version: 11.5
W0405 08:31:56.570864 2488335 gpu_resources.cc:91] device: 7, cuDNN Version: 8.5.
git:
  sha: ed03951a885c784a1cdd55afb95472c7e6f17404, status: has uncommited changes, branch: master

act_in_head: gelu
arch: vit_small
batch_size_per_gpu: 64
clip_grad: 3.0
data_path: /home/xiejunlin/data/datasets/imagenet/mini/train
drop_path: 0.1
epochs: 800
freeze_last_layer: 1
global_crops_number: 2
global_crops_scale: [0.25, 1.0]
lambda1: 1.0
lambda2: 1.0
local_crops_number: 10
local_crops_scale: [0.05, 0.25]
local_rank: 0
lr: 0.0005
min_lr: 1e-06
momentum_teacher: 0.996
norm_in_head: None
norm_last_layer: False
num_workers: 10
optimizer: adamw
out_dim: 8192
output_dir: ./output
patch_out_dim: 8192
patch_size: 16
pred_ratio: [0.0, 0.3]
pred_ratio_var: [0.0, 0.2]
pred_shape: block
pred_start_epoch: 0
resume_path: None
saveckp_freq: 20
seed: 0
shared_head: True
shared_head_teacher: True
teacher_patch_temp: 0.07
teacher_temp: 0.07
use_fp16: True
use_masked_im_modeling: True
warmup_epochs: 10
warmup_teacher_patch_temp: 0.04
warmup_teacher_temp: 0.04
warmup_teacher_temp_epochs: 30
weight_decay: 0.04
weight_decay_end: 0.4
window_size: 7
Traceback (most recent call last):
  File "main_ibot.py", line 475, in <module>
    train_ibot(args)
  File "main_ibot.py", line 184, in train_ibot
    dataset, args.batch_size, shuffle=True, drop_last=True
AttributeError: 'Namespace' object has no attribute 'batch_size'
I0405 08:33:28.979558 2497116 tcp_utils.cc:130] Successfully connected to 127.0.1.1:51131
W0405 08:33:32.230620 2497116 gpu_resources.cc:61] Please NOTE: device: 7, GPU Compute Capability: 8.6, Driver API Version: 11.5, Runtime API Version: 11.5
W0405 08:33:32.238250 2497116 gpu_resources.cc:91] device: 7, cuDNN Version: 8.5.
git:
  sha: ed03951a885c784a1cdd55afb95472c7e6f17404, status: has uncommited changes, branch: master

act_in_head: gelu
arch: vit_small
batch_size_per_gpu: 64
clip_grad: 3.0
data_path: /home/xiejunlin/data/datasets/imagenet/mini/train
drop_path: 0.1
epochs: 800
freeze_last_layer: 1
global_crops_number: 2
global_crops_scale: [0.25, 1.0]
lambda1: 1.0
lambda2: 1.0
local_crops_number: 10
local_crops_scale: [0.05, 0.25]
local_rank: 0
lr: 0.0005
min_lr: 1e-06
momentum_teacher: 0.996
norm_in_head: None
norm_last_layer: False
num_workers: 10
optimizer: adamw
out_dim: 8192
output_dir: ./output
patch_out_dim: 8192
patch_size: 16
pred_ratio: [0.0, 0.3]
pred_ratio_var: [0.0, 0.2]
pred_shape: block
pred_start_epoch: 0
resume_path: None
saveckp_freq: 20
seed: 0
shared_head: True
shared_head_teacher: True
teacher_patch_temp: 0.07
teacher_temp: 0.07
use_fp16: True
use_masked_im_modeling: True
warmup_epochs: 10
warmup_teacher_patch_temp: 0.04
warmup_teacher_temp: 0.04
warmup_teacher_temp_epochs: 30
weight_decay: 0.04
weight_decay_end: 0.4
window_size: 7
Data loaded: there are 34745 images.
Unknow architecture: vit_small
Traceback (most recent call last):
  File "main_ibot.py", line 475, in <module>
    train_ibot(args)
  File "main_ibot.py", line 225, in train_ibot
    student, 
UnboundLocalError: local variable 'student' referenced before assignment
usage: iBOT [-h]
            [--arch {vit_tiny,vit_small,vit_base,vit_large,deit_tiny,deit_small,swin_tiny,swin_small,swin_base,swin_large}]
            [--patch_size PATCH_SIZE] [--window_size WINDOW_SIZE]
            [--out_dim OUT_DIM] [--patch_out_dim PATCH_OUT_DIM]
            [--shared_head SHARED_HEAD]
            [--shared_head_teacher SHARED_HEAD_TEACHER]
            [--norm_last_layer NORM_LAST_LAYER]
            [--momentum_teacher MOMENTUM_TEACHER]
            [--norm_in_head NORM_IN_HEAD] [--act_in_head ACT_IN_HEAD]
            [--use_masked_im_modeling USE_MASKED_IM_MODELING]
            [--pred_ratio PRED_RATIO [PRED_RATIO ...]]
            [--pred_ratio_var PRED_RATIO_VAR [PRED_RATIO_VAR ...]]
            [--pred_shape PRED_SHAPE] [--pred_start_epoch PRED_START_EPOCH]
            [--lambda1 LAMBDA1] [--lambda2 LAMBDA2]
            [--warmup_teacher_temp WARMUP_TEACHER_TEMP]
            [--teacher_temp TEACHER_TEMP]
            [--warmup_teacher_patch_temp WARMUP_TEACHER_PATCH_TEMP]
            [--teacher_patch_temp TEACHER_PATCH_TEMP]
            [--warmup_teacher_temp_epochs WARMUP_TEACHER_TEMP_EPOCHS]
            [--use_fp16 USE_FP16] [--weight_decay WEIGHT_DECAY]
            [--weight_decay_end WEIGHT_DECAY_END] [--clip_grad CLIP_GRAD]
            [--batch_size_per_gpu BATCH_SIZE_PER_GPU] [--epochs EPOCHS]
            [--freeze_last_layer FREEZE_LAST_LAYER] [--lr LR]
            [--warmup_epochs WARMUP_EPOCHS] [--min_lr MIN_LR]
            [--optimizer {adamw,sgd,lars}] [--drop_path DROP_PATH]
            [--global_crops_number GLOBAL_CROPS_NUMBER]
            [--global_crops_scale GLOBAL_CROPS_SCALE [GLOBAL_CROPS_SCALE ...]]
            [--local_crops_number LOCAL_CROPS_NUMBER]
            [--local_crops_scale LOCAL_CROPS_SCALE [LOCAL_CROPS_SCALE ...]]
            [--resume_path RESUME_PATH] [--data_path DATA_PATH]
            [--output_dir OUTPUT_DIR] [--saveckp_freq SAVECKP_FREQ]
            [--seed SEED] [--num_workers NUM_WORKERS]
            [--local_rank LOCAL_RANK]
iBOT: error: argument --arch: invalid choice: 'IBOT_ViT_small_patch16_224' (choose from 'vit_tiny', 'vit_small', 'vit_base', 'vit_large', 'deit_tiny', 'deit_small', 'swin_tiny', 'swin_small', 'swin_base', 'swin_large')
I0405 09:37:57.632642 2819893 tcp_utils.cc:130] Successfully connected to 127.0.1.1:37490
W0405 09:38:00.845790 2819893 gpu_resources.cc:61] Please NOTE: device: 7, GPU Compute Capability: 8.6, Driver API Version: 11.5, Runtime API Version: 11.5
W0405 09:38:00.853960 2819893 gpu_resources.cc:91] device: 7, cuDNN Version: 8.5.
git:
  sha: ed03951a885c784a1cdd55afb95472c7e6f17404, status: has uncommited changes, branch: master

act_in_head: gelu
arch: vit_small
batch_size_per_gpu: 64
clip_grad: 3.0
data_path: /home/xiejunlin/data/datasets/imagenet/mini/train
drop_path: 0.1
epochs: 800
freeze_last_layer: 1
global_crops_number: 2
global_crops_scale: [0.25, 1.0]
lambda1: 1.0
lambda2: 1.0
local_crops_number: 10
local_crops_scale: [0.05, 0.25]
local_rank: 0
lr: 0.0005
min_lr: 1e-06
momentum_teacher: 0.996
norm_in_head: None
norm_last_layer: False
num_workers: 10
optimizer: adamw
out_dim: 8192
output_dir: ./output
patch_out_dim: 8192
patch_size: 16
pred_ratio: [0.0, 0.3]
pred_ratio_var: [0.0, 0.2]
pred_shape: block
pred_start_epoch: 0
resume_path: 
saveckp_freq: 20
seed: 0
shared_head: True
shared_head_teacher: True
teacher_patch_temp: 0.07
teacher_temp: 0.07
use_fp16: True
use_masked_im_modeling: True
warmup_epochs: 10
warmup_teacher_patch_temp: 0.04
warmup_teacher_temp: 0.04
warmup_teacher_temp_epochs: 30
weight_decay: 0.04
weight_decay_end: 0.4
window_size: 7
Data loaded: there are 34745 images.
Student and Teacher are built: they are both vit_small network.
Loss, optimizer and schedulers ready.
Starting IBOT training!
W0405 09:38:23.424062 2819893 reducer.cc:633] There is no parameter in the device involved in the backward calculation. If there are parameters on other devices involved in the backward, then a serious error will occur here.
Traceback (most recent call last):
  File "main_ibot.py", line 475, in <module>
    train_ibot(args)
  File "main_ibot.py", line 327, in train_ibot
    train_stats = train_one_epoch(
  File "main_ibot.py", line 407, in train_one_epoch
    student.module.backbone.masked_im_modeling = False
  File "/home/xiejunlin/miniconda3/envs/torch/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py", line 1234, in __getattr__
    return object.__getattribute__(self, name)
AttributeError: 'DataParallel' object has no attribute 'module'
I0405 09:44:32.393144 2853034 tcp_utils.cc:107] Retry to connect to 127.0.1.1:58009 while the server is not yet listening.
I0405 09:44:35.393513 2853034 tcp_utils.cc:130] Successfully connected to 127.0.1.1:58009
W0405 09:44:38.555759 2853034 gpu_resources.cc:61] Please NOTE: device: 7, GPU Compute Capability: 8.6, Driver API Version: 11.5, Runtime API Version: 11.5
W0405 09:44:38.562985 2853034 gpu_resources.cc:91] device: 7, cuDNN Version: 8.5.
git:
  sha: ed03951a885c784a1cdd55afb95472c7e6f17404, status: has uncommited changes, branch: master

act_in_head: gelu
arch: vit_small
batch_size_per_gpu: 64
clip_grad: 3.0
data_path: /home/xiejunlin/data/datasets/imagenet/mini/train
drop_path: 0.1
epochs: 800
freeze_last_layer: 1
global_crops_number: 2
global_crops_scale: [0.25, 1.0]
lambda1: 1.0
lambda2: 1.0
local_crops_number: 10
local_crops_scale: [0.05, 0.25]
local_rank: 0
lr: 0.0005
min_lr: 1e-06
momentum_teacher: 0.996
norm_in_head: None
norm_last_layer: False
num_workers: 10
optimizer: adamw
out_dim: 8192
output_dir: ./output
patch_out_dim: 8192
patch_size: 16
pred_ratio: [0.0, 0.3]
pred_ratio_var: [0.0, 0.2]
pred_shape: block
pred_start_epoch: 0
resume_path: 
saveckp_freq: 20
seed: 0
shared_head: True
shared_head_teacher: True
teacher_patch_temp: 0.07
teacher_temp: 0.07
use_fp16: True
use_masked_im_modeling: True
warmup_epochs: 10
warmup_teacher_patch_temp: 0.04
warmup_teacher_temp: 0.04
warmup_teacher_temp_epochs: 30
weight_decay: 0.04
weight_decay_end: 0.4
window_size: 7
Data loaded: there are 34745 images.
Student and Teacher are built: they are both vit_small network.
Loss, optimizer and schedulers ready.
Starting IBOT training!
W0405 09:44:50.680111 2853034 reducer.cc:633] There is no parameter in the device involved in the backward calculation. If there are parameters on other devices involved in the backward, then a serious error will occur here.
Traceback (most recent call last):
  File "main_ibot.py", line 475, in <module>
    train_ibot(args)
  File "main_ibot.py", line 327, in train_ibot
    train_stats = train_one_epoch(
  File "main_ibot.py", line 408, in train_one_epoch
    student_local_cls = student(images[args.global_crops_number:])[0] if len(images) > args.global_crops_number else None
  File "/home/xiejunlin/miniconda3/envs/torch/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py", line 1012, in __call__
    return self.forward(*inputs, **kwargs)
  File "/home/xiejunlin/miniconda3/envs/torch/lib/python3.8/site-packages/paddle/fluid/dygraph/parallel.py", line 774, in forward
    outputs = self._layers(*inputs, **kwargs)
  File "/home/xiejunlin/miniconda3/envs/torch/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py", line 1012, in __call__
    return self.forward(*inputs, **kwargs)
  File "/home/xiejunlin/workspace/IBOT-Paddle/models/ibot.py", line 84, in forward
    _out = self.backbone(inp_x, **kwargs)
  File "/home/xiejunlin/miniconda3/envs/torch/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py", line 1012, in __call__
    return self.forward(*inputs, **kwargs)
  File "/home/xiejunlin/workspace/IBOT-Paddle/models/ibot.py", line 208, in forward
    x = self.forward_features(x, mask, return_all_tokens=self.return_all_tokens)
  File "/home/xiejunlin/workspace/IBOT-Paddle/models/ibot.py", line 174, in forward_features
    x = self.patch_embed(x)
  File "/home/xiejunlin/miniconda3/envs/torch/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py", line 1012, in __call__
    return self.forward(*inputs, **kwargs)
  File "/home/xiejunlin/workspace/IBOT-Paddle/models/vision_transformer.py", line 198, in forward
    assert H == self.img_size[0] and W == self.img_size[1], \
AssertionError: Input image size (96*96) doesn't match model (224*224).
I0405 09:49:00.238394 2874717 tcp_utils.cc:130] Successfully connected to 127.0.1.1:35168
W0405 09:49:06.354261 2874717 gpu_resources.cc:61] Please NOTE: device: 7, GPU Compute Capability: 8.6, Driver API Version: 11.5, Runtime API Version: 11.5
W0405 09:49:06.361742 2874717 gpu_resources.cc:91] device: 7, cuDNN Version: 8.5.
git:
  sha: ed03951a885c784a1cdd55afb95472c7e6f17404, status: has uncommited changes, branch: master

act_in_head: gelu
arch: vit_small
batch_size_per_gpu: 64
clip_grad: 3.0
data_path: /home/xiejunlin/data/datasets/imagenet/mini/train
drop_path: 0.1
epochs: 800
freeze_last_layer: 1
global_crops_number: 2
global_crops_scale: [0.25, 1.0]
lambda1: 1.0
lambda2: 1.0
local_crops_number: 10
local_crops_scale: [0.05, 0.25]
local_rank: 0
lr: 0.0005
min_lr: 1e-06
momentum_teacher: 0.996
norm_in_head: None
norm_last_layer: False
num_workers: 10
optimizer: adamw
out_dim: 8192
output_dir: ./output
patch_out_dim: 8192
patch_size: 16
pred_ratio: [0.0, 0.3]
pred_ratio_var: [0.0, 0.2]
pred_shape: block
pred_start_epoch: 0
resume_path: 
saveckp_freq: 20
seed: 0
shared_head: True
shared_head_teacher: True
teacher_patch_temp: 0.07
teacher_temp: 0.07
use_fp16: True
use_masked_im_modeling: True
warmup_epochs: 10
warmup_teacher_patch_temp: 0.04
warmup_teacher_temp: 0.04
warmup_teacher_temp_epochs: 30
weight_decay: 0.04
weight_decay_end: 0.4
window_size: 7
Data loaded: there are 34745 images.
Student and Teacher are built: they are both vit_small network.
Loss, optimizer and schedulers ready.
Starting IBOT training!
W0405 09:49:18.805282 2874717 reducer.cc:633] There is no parameter in the device involved in the backward calculation. If there are parameters on other devices involved in the backward, then a serious error will occur here.
Traceback (most recent call last):
  File "main_ibot.py", line 475, in <module>
    train_ibot(args)
  File "main_ibot.py", line 327, in train_ibot
    train_stats = train_one_epoch(
  File "main_ibot.py", line 408, in train_one_epoch
    student_local_cls = student(images[args.global_crops_number:])[0] if len(images) > args.global_crops_number else None
  File "/home/xiejunlin/miniconda3/envs/torch/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py", line 1012, in __call__
    return self.forward(*inputs, **kwargs)
  File "/home/xiejunlin/miniconda3/envs/torch/lib/python3.8/site-packages/paddle/fluid/dygraph/parallel.py", line 774, in forward
    outputs = self._layers(*inputs, **kwargs)
  File "/home/xiejunlin/miniconda3/envs/torch/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py", line 1012, in __call__
    return self.forward(*inputs, **kwargs)
  File "/home/xiejunlin/workspace/IBOT-Paddle/models/ibot.py", line 84, in forward
    _out = self.backbone(inp_x, **kwargs)
  File "/home/xiejunlin/miniconda3/envs/torch/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py", line 1012, in __call__
    return self.forward(*inputs, **kwargs)
  File "/home/xiejunlin/workspace/IBOT-Paddle/models/ibot.py", line 208, in forward
    x = self.forward_features(x, mask, return_all_tokens=self.return_all_tokens)
  File "/home/xiejunlin/workspace/IBOT-Paddle/models/ibot.py", line 178, in forward_features
    x = x.reshape([C,N,H,W])
  File "/home/xiejunlin/miniconda3/envs/torch/lib/python3.8/site-packages/paddle/tensor/manipulation.py", line 3543, in reshape
    out = _C_ops.reshape(x, shape)
ValueError: (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [640, 384, 36], X's size = 8847360, 'shape' is [640, 384, 14, 14], the capacity of 'shape' is 48168960.
  [Hint: Expected capacity == in_size, but received capacity:48168960 != in_size:8847360.] (at /paddle/paddle/phi/infermeta/unary.cc:1435)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Termination signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1680688162 (unix time) try "date -d @1680688162" if you are using GNU date ***]
  [SignalInfo: *** SIGTERM (@0x3f4002bdc34) received by PID 2874717 (TID 0x7f7e17a1c4c0) from PID 2874420 ***]

