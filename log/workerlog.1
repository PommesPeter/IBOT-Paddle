Traceback (most recent call last):
  File "main_ibot.py", line 29, in <module>
    import models
  File "/home/xiejunlin/workspace/IBOT-Paddle/models/__init__.py", line 3, in <module>
    from ibot import IBOT_ViT_small_patch16_224
ModuleNotFoundError: No module named 'ibot'
Traceback (most recent call last):
  File "main_ibot.py", line 29, in <module>
    import models
  File "/home/xiejunlin/workspace/IBOT-Paddle/models/__init__.py", line 3, in <module>
    from .ibot import IBOT_ViT_small_patch16_224
  File "/home/xiejunlin/workspace/IBOT-Paddle/models/ibot.py", line 23, in <module>
    from .utils import (load_dygraph_pretrain,
  File "/home/xiejunlin/workspace/IBOT-Paddle/models/utils.py", line 21, in <module>
    from .download import get_weights_path_from_url
  File "/home/xiejunlin/workspace/IBOT-Paddle/models/download.py", line 31, in <module>
    from . import logger
ImportError: cannot import name 'logger' from partially initialized module 'models' (most likely due to a circular import) (/home/xiejunlin/workspace/IBOT-Paddle/models/__init__.py)
Traceback (most recent call last):
  File "main_ibot.py", line 30, in <module>
    import utils
  File "/home/xiejunlin/workspace/IBOT-Paddle/utils.py", line 526, in <module>
    class LARS(paddle.optimizer.Optimizer):
  File "/home/xiejunlin/workspace/IBOT-Paddle/utils.py", line 537, in LARS
    @torch.no_grad()
NameError: name 'torch' is not defined
I0405 08:13:37.088292 2400182 tcp_utils.cc:130] Successfully connected to 127.0.1.1:53014
Traceback (most recent call last):
  File "main_ibot.py", line 475, in <module>
    train_ibot(args)
  File "main_ibot.py", line 160, in train_ibot
    dist.init_parallel_env()
  File "/home/xiejunlin/miniconda3/envs/torch/lib/python3.8/site-packages/paddle/distributed/parallel.py", line 297, in init_parallel_env
    paddle.distributed.barrier(group=group)
  File "/home/xiejunlin/miniconda3/envs/torch/lib/python3.8/site-packages/paddle/distributed/collective.py", line 280, in barrier
    task = group.process_group.barrier()
ValueError: (InvalidArgument) TCP send error. Details: Broken pipe.
  [Hint: Expected byte_sent > 0, but received byte_sent:-1 <= 0:0.] (at /paddle/paddle/fluid/distributed/store/tcp_utils.h:86)

I0405 08:31:50.036896 2488326 tcp_utils.cc:107] Retry to connect to 127.0.1.1:54371 while the server is not yet listening.
I0405 08:31:53.037288 2488326 tcp_utils.cc:130] Successfully connected to 127.0.1.1:54371
W0405 08:31:56.741673 2488326 gpu_resources.cc:61] Please NOTE: device: 5, GPU Compute Capability: 8.6, Driver API Version: 11.5, Runtime API Version: 11.5
W0405 08:31:56.749027 2488326 gpu_resources.cc:91] device: 5, cuDNN Version: 8.5.
git:
  sha: ed03951a885c784a1cdd55afb95472c7e6f17404, status: has uncommited changes, branch: master

act_in_head: gelu
arch: vit_small
batch_size_per_gpu: 64
clip_grad: 3.0
data_path: /home/xiejunlin/data/datasets/imagenet/mini/train
drop_path: 0.1
epochs: 800
freeze_last_layer: 1
global_crops_number: 2
global_crops_scale: [0.25, 1.0]
lambda1: 1.0
lambda2: 1.0
local_crops_number: 10
local_crops_scale: [0.05, 0.25]
local_rank: 0
lr: 0.0005
min_lr: 1e-06
momentum_teacher: 0.996
norm_in_head: None
norm_last_layer: False
num_workers: 10
optimizer: adamw
out_dim: 8192
output_dir: ./output
patch_out_dim: 8192
patch_size: 16
pred_ratio: [0.0, 0.3]
pred_ratio_var: [0.0, 0.2]
pred_shape: block
pred_start_epoch: 0
resume_path: None
saveckp_freq: 20
seed: 0
shared_head: True
shared_head_teacher: True
teacher_patch_temp: 0.07
teacher_temp: 0.07
use_fp16: True
use_masked_im_modeling: True
warmup_epochs: 10
warmup_teacher_patch_temp: 0.04
warmup_teacher_temp: 0.04
warmup_teacher_temp_epochs: 30
weight_decay: 0.04
weight_decay_end: 0.4
window_size: 7
Traceback (most recent call last):
  File "main_ibot.py", line 475, in <module>
    train_ibot(args)
  File "main_ibot.py", line 184, in train_ibot
    dataset, args.batch_size, shuffle=True, drop_last=True
AttributeError: 'Namespace' object has no attribute 'batch_size'
I0405 08:33:28.819909 2497112 tcp_utils.cc:130] Successfully connected to 127.0.1.1:51131
W0405 08:33:32.908166 2497112 gpu_resources.cc:61] Please NOTE: device: 5, GPU Compute Capability: 8.6, Driver API Version: 11.5, Runtime API Version: 11.5
W0405 08:33:32.914714 2497112 gpu_resources.cc:91] device: 5, cuDNN Version: 8.5.
git:
  sha: ed03951a885c784a1cdd55afb95472c7e6f17404, status: has uncommited changes, branch: master

act_in_head: gelu
arch: vit_small
batch_size_per_gpu: 64
clip_grad: 3.0
data_path: /home/xiejunlin/data/datasets/imagenet/mini/train
drop_path: 0.1
epochs: 800
freeze_last_layer: 1
global_crops_number: 2
global_crops_scale: [0.25, 1.0]
lambda1: 1.0
lambda2: 1.0
local_crops_number: 10
local_crops_scale: [0.05, 0.25]
local_rank: 0
lr: 0.0005
min_lr: 1e-06
momentum_teacher: 0.996
norm_in_head: None
norm_last_layer: False
num_workers: 10
optimizer: adamw
out_dim: 8192
output_dir: ./output
patch_out_dim: 8192
patch_size: 16
pred_ratio: [0.0, 0.3]
pred_ratio_var: [0.0, 0.2]
pred_shape: block
pred_start_epoch: 0
resume_path: None
saveckp_freq: 20
seed: 0
shared_head: True
shared_head_teacher: True
teacher_patch_temp: 0.07
teacher_temp: 0.07
use_fp16: True
use_masked_im_modeling: True
warmup_epochs: 10
warmup_teacher_patch_temp: 0.04
warmup_teacher_temp: 0.04
warmup_teacher_temp_epochs: 30
weight_decay: 0.04
weight_decay_end: 0.4
window_size: 7
Data loaded: there are 34745 images.
Unknow architecture: vit_small
Traceback (most recent call last):
  File "main_ibot.py", line 475, in <module>
    train_ibot(args)
  File "main_ibot.py", line 225, in train_ibot
    student, 
UnboundLocalError: local variable 'student' referenced before assignment
usage: iBOT [-h]
            [--arch {vit_tiny,vit_small,vit_base,vit_large,deit_tiny,deit_small,swin_tiny,swin_small,swin_base,swin_large}]
            [--patch_size PATCH_SIZE] [--window_size WINDOW_SIZE]
            [--out_dim OUT_DIM] [--patch_out_dim PATCH_OUT_DIM]
            [--shared_head SHARED_HEAD]
            [--shared_head_teacher SHARED_HEAD_TEACHER]
            [--norm_last_layer NORM_LAST_LAYER]
            [--momentum_teacher MOMENTUM_TEACHER]
            [--norm_in_head NORM_IN_HEAD] [--act_in_head ACT_IN_HEAD]
            [--use_masked_im_modeling USE_MASKED_IM_MODELING]
            [--pred_ratio PRED_RATIO [PRED_RATIO ...]]
            [--pred_ratio_var PRED_RATIO_VAR [PRED_RATIO_VAR ...]]
            [--pred_shape PRED_SHAPE] [--pred_start_epoch PRED_START_EPOCH]
            [--lambda1 LAMBDA1] [--lambda2 LAMBDA2]
            [--warmup_teacher_temp WARMUP_TEACHER_TEMP]
            [--teacher_temp TEACHER_TEMP]
            [--warmup_teacher_patch_temp WARMUP_TEACHER_PATCH_TEMP]
            [--teacher_patch_temp TEACHER_PATCH_TEMP]
            [--warmup_teacher_temp_epochs WARMUP_TEACHER_TEMP_EPOCHS]
            [--use_fp16 USE_FP16] [--weight_decay WEIGHT_DECAY]
            [--weight_decay_end WEIGHT_DECAY_END] [--clip_grad CLIP_GRAD]
            [--batch_size_per_gpu BATCH_SIZE_PER_GPU] [--epochs EPOCHS]
            [--freeze_last_layer FREEZE_LAST_LAYER] [--lr LR]
            [--warmup_epochs WARMUP_EPOCHS] [--min_lr MIN_LR]
            [--optimizer {adamw,sgd,lars}] [--drop_path DROP_PATH]
            [--global_crops_number GLOBAL_CROPS_NUMBER]
            [--global_crops_scale GLOBAL_CROPS_SCALE [GLOBAL_CROPS_SCALE ...]]
            [--local_crops_number LOCAL_CROPS_NUMBER]
            [--local_crops_scale LOCAL_CROPS_SCALE [LOCAL_CROPS_SCALE ...]]
            [--resume_path RESUME_PATH] [--data_path DATA_PATH]
            [--output_dir OUTPUT_DIR] [--saveckp_freq SAVECKP_FREQ]
            [--seed SEED] [--num_workers NUM_WORKERS]
            [--local_rank LOCAL_RANK]
iBOT: error: argument --arch: invalid choice: 'IBOT_ViT_small_patch16_224' (choose from 'vit_tiny', 'vit_small', 'vit_base', 'vit_large', 'deit_tiny', 'deit_small', 'swin_tiny', 'swin_small', 'swin_base', 'swin_large')
I0405 09:37:57.679087 2819889 tcp_utils.cc:130] Successfully connected to 127.0.1.1:37490
W0405 09:38:01.307760 2819889 gpu_resources.cc:61] Please NOTE: device: 5, GPU Compute Capability: 8.6, Driver API Version: 11.5, Runtime API Version: 11.5
W0405 09:38:01.316200 2819889 gpu_resources.cc:91] device: 5, cuDNN Version: 8.5.
git:
  sha: ed03951a885c784a1cdd55afb95472c7e6f17404, status: has uncommited changes, branch: master

act_in_head: gelu
arch: vit_small
batch_size_per_gpu: 64
clip_grad: 3.0
data_path: /home/xiejunlin/data/datasets/imagenet/mini/train
drop_path: 0.1
epochs: 800
freeze_last_layer: 1
global_crops_number: 2
global_crops_scale: [0.25, 1.0]
lambda1: 1.0
lambda2: 1.0
local_crops_number: 10
local_crops_scale: [0.05, 0.25]
local_rank: 0
lr: 0.0005
min_lr: 1e-06
momentum_teacher: 0.996
norm_in_head: None
norm_last_layer: False
num_workers: 10
optimizer: adamw
out_dim: 8192
output_dir: ./output
patch_out_dim: 8192
patch_size: 16
pred_ratio: [0.0, 0.3]
pred_ratio_var: [0.0, 0.2]
pred_shape: block
pred_start_epoch: 0
resume_path: 
saveckp_freq: 20
seed: 0
shared_head: True
shared_head_teacher: True
teacher_patch_temp: 0.07
teacher_temp: 0.07
use_fp16: True
use_masked_im_modeling: True
warmup_epochs: 10
warmup_teacher_patch_temp: 0.04
warmup_teacher_temp: 0.04
warmup_teacher_temp_epochs: 30
weight_decay: 0.04
weight_decay_end: 0.4
window_size: 7
Data loaded: there are 34745 images.
Student and Teacher are built: they are both vit_small network.
Loss, optimizer and schedulers ready.
Starting IBOT training!


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   bvar::detail::SamplerCollector::sampling_thread(void*)
1   bvar::detail::SamplerCollector::run()

----------------------
Error Message Summary:
----------------------
FatalError: `Termination signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1680687507 (unix time) try "date -d @1680687507" if you are using GNU date ***]
  [SignalInfo: *** SIGTERM (@0x3f4002b0606) received by PID 2819889 (TID 0x7fd856774700) from PID 2819590 ***]

I0405 09:44:32.497287 2853028 tcp_utils.cc:130] Successfully connected to 127.0.1.1:58009
W0405 09:44:38.954162 2853028 gpu_resources.cc:61] Please NOTE: device: 5, GPU Compute Capability: 8.6, Driver API Version: 11.5, Runtime API Version: 11.5
W0405 09:44:38.961228 2853028 gpu_resources.cc:91] device: 5, cuDNN Version: 8.5.
git:
  sha: ed03951a885c784a1cdd55afb95472c7e6f17404, status: has uncommited changes, branch: master

act_in_head: gelu
arch: vit_small
batch_size_per_gpu: 64
clip_grad: 3.0
data_path: /home/xiejunlin/data/datasets/imagenet/mini/train
drop_path: 0.1
epochs: 800
freeze_last_layer: 1
global_crops_number: 2
global_crops_scale: [0.25, 1.0]
lambda1: 1.0
lambda2: 1.0
local_crops_number: 10
local_crops_scale: [0.05, 0.25]
local_rank: 0
lr: 0.0005
min_lr: 1e-06
momentum_teacher: 0.996
norm_in_head: None
norm_last_layer: False
num_workers: 10
optimizer: adamw
out_dim: 8192
output_dir: ./output
patch_out_dim: 8192
patch_size: 16
pred_ratio: [0.0, 0.3]
pred_ratio_var: [0.0, 0.2]
pred_shape: block
pred_start_epoch: 0
resume_path: 
saveckp_freq: 20
seed: 0
shared_head: True
shared_head_teacher: True
teacher_patch_temp: 0.07
teacher_temp: 0.07
use_fp16: True
use_masked_im_modeling: True
warmup_epochs: 10
warmup_teacher_patch_temp: 0.04
warmup_teacher_temp: 0.04
warmup_teacher_temp_epochs: 30
weight_decay: 0.04
weight_decay_end: 0.4
window_size: 7
Data loaded: there are 34745 images.
Student and Teacher are built: they are both vit_small network.
Loss, optimizer and schedulers ready.
Starting IBOT training!
W0405 09:44:52.158071 2853028 reducer.cc:633] There is no parameter in the device involved in the backward calculation. If there are parameters on other devices involved in the backward, then a serious error will occur here.
Traceback (most recent call last):
  File "main_ibot.py", line 475, in <module>
    train_ibot(args)
  File "main_ibot.py", line 327, in train_ibot
    train_stats = train_one_epoch(
  File "main_ibot.py", line 408, in train_one_epoch
    student_local_cls = student(images[args.global_crops_number:])[0] if len(images) > args.global_crops_number else None
  File "/home/xiejunlin/miniconda3/envs/torch/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py", line 1012, in __call__
    return self.forward(*inputs, **kwargs)
  File "/home/xiejunlin/miniconda3/envs/torch/lib/python3.8/site-packages/paddle/fluid/dygraph/parallel.py", line 774, in forward
    outputs = self._layers(*inputs, **kwargs)
  File "/home/xiejunlin/miniconda3/envs/torch/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py", line 1012, in __call__
    return self.forward(*inputs, **kwargs)
  File "/home/xiejunlin/workspace/IBOT-Paddle/models/ibot.py", line 84, in forward
    _out = self.backbone(inp_x, **kwargs)
  File "/home/xiejunlin/miniconda3/envs/torch/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py", line 1012, in __call__
    return self.forward(*inputs, **kwargs)
  File "/home/xiejunlin/workspace/IBOT-Paddle/models/ibot.py", line 208, in forward
    x = self.forward_features(x, mask, return_all_tokens=self.return_all_tokens)
  File "/home/xiejunlin/workspace/IBOT-Paddle/models/ibot.py", line 174, in forward_features
    x = self.patch_embed(x)
  File "/home/xiejunlin/miniconda3/envs/torch/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py", line 1012, in __call__
    return self.forward(*inputs, **kwargs)
  File "/home/xiejunlin/workspace/IBOT-Paddle/models/vision_transformer.py", line 198, in forward
    assert H == self.img_size[0] and W == self.img_size[1], \
AssertionError: Input image size (96*96) doesn't match model (224*224).
Exception in thread Thread-1:
Traceback (most recent call last):
  File "/home/xiejunlin/miniconda3/envs/torch/lib/python3.8/site-packages/paddle/fluid/dataloader/dataloader_iter.py", line 623, in _get_data
    data = self._data_queue.get(timeout=self._timeout)
  File "/home/xiejunlin/miniconda3/envs/torch/lib/python3.8/multiprocessing/queues.py", line 108, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/xiejunlin/miniconda3/envs/torch/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/xiejunlin/miniconda3/envs/torch/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/xiejunlin/miniconda3/envs/torch/lib/python3.8/site-packages/paddle/fluid/dataloader/dataloader_iter.py", line 536, in _thread_loop
    batch = self._get_data()
  File "/home/xiejunlin/miniconda3/envs/torch/lib/python3.8/site-packages/paddle/fluid/dataloader/dataloader_iter.py", line 638, in _get_data
    raise RuntimeError("DataLoader {} workers exit unexpectedly, " \
RuntimeError: DataLoader 9 workers exit unexpectedly, pids: 2854112, 2854116, 2854135, 2854139, 2854141, 2854158, 2854162, 2854177, 2854179


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Termination signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1680687893 (unix time) try "date -d @1680687893" if you are using GNU date ***]
  [SignalInfo: *** SIGTERM (@0x3f4002b8754) received by PID 2853028 (TID 0x7ff2cd4634c0) from PID 2852692 ***]

I0405 09:49:00.038928 2874713 tcp_utils.cc:107] Retry to connect to 127.0.1.1:35168 while the server is not yet listening.
I0405 09:49:03.039247 2874713 tcp_utils.cc:130] Successfully connected to 127.0.1.1:35168
W0405 09:49:06.445801 2874713 gpu_resources.cc:61] Please NOTE: device: 5, GPU Compute Capability: 8.6, Driver API Version: 11.5, Runtime API Version: 11.5
W0405 09:49:06.453084 2874713 gpu_resources.cc:91] device: 5, cuDNN Version: 8.5.
git:
  sha: ed03951a885c784a1cdd55afb95472c7e6f17404, status: has uncommited changes, branch: master

act_in_head: gelu
arch: vit_small
batch_size_per_gpu: 64
clip_grad: 3.0
data_path: /home/xiejunlin/data/datasets/imagenet/mini/train
drop_path: 0.1
epochs: 800
freeze_last_layer: 1
global_crops_number: 2
global_crops_scale: [0.25, 1.0]
lambda1: 1.0
lambda2: 1.0
local_crops_number: 10
local_crops_scale: [0.05, 0.25]
local_rank: 0
lr: 0.0005
min_lr: 1e-06
momentum_teacher: 0.996
norm_in_head: None
norm_last_layer: False
num_workers: 10
optimizer: adamw
out_dim: 8192
output_dir: ./output
patch_out_dim: 8192
patch_size: 16
pred_ratio: [0.0, 0.3]
pred_ratio_var: [0.0, 0.2]
pred_shape: block
pred_start_epoch: 0
resume_path: 
saveckp_freq: 20
seed: 0
shared_head: True
shared_head_teacher: True
teacher_patch_temp: 0.07
teacher_temp: 0.07
use_fp16: True
use_masked_im_modeling: True
warmup_epochs: 10
warmup_teacher_patch_temp: 0.04
warmup_teacher_temp: 0.04
warmup_teacher_temp_epochs: 30
weight_decay: 0.04
weight_decay_end: 0.4
window_size: 7
Data loaded: there are 34745 images.
Student and Teacher are built: they are both vit_small network.
Loss, optimizer and schedulers ready.
Starting IBOT training!
W0405 09:49:19.015887 2874713 reducer.cc:633] There is no parameter in the device involved in the backward calculation. If there are parameters on other devices involved in the backward, then a serious error will occur here.
Traceback (most recent call last):
  File "main_ibot.py", line 475, in <module>
    train_ibot(args)
  File "main_ibot.py", line 327, in train_ibot
    train_stats = train_one_epoch(
  File "main_ibot.py", line 408, in train_one_epoch
    student_local_cls = student(images[args.global_crops_number:])[0] if len(images) > args.global_crops_number else None
  File "/home/xiejunlin/miniconda3/envs/torch/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py", line 1012, in __call__
    return self.forward(*inputs, **kwargs)
  File "/home/xiejunlin/miniconda3/envs/torch/lib/python3.8/site-packages/paddle/fluid/dygraph/parallel.py", line 774, in forward
    outputs = self._layers(*inputs, **kwargs)
  File "/home/xiejunlin/miniconda3/envs/torch/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py", line 1012, in __call__
    return self.forward(*inputs, **kwargs)
  File "/home/xiejunlin/workspace/IBOT-Paddle/models/ibot.py", line 84, in forward
    _out = self.backbone(inp_x, **kwargs)
  File "/home/xiejunlin/miniconda3/envs/torch/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py", line 1012, in __call__
    return self.forward(*inputs, **kwargs)
  File "/home/xiejunlin/workspace/IBOT-Paddle/models/ibot.py", line 208, in forward
    x = self.forward_features(x, mask, return_all_tokens=self.return_all_tokens)
  File "/home/xiejunlin/workspace/IBOT-Paddle/models/ibot.py", line 178, in forward_features
    x = x.reshape([C,N,H,W])
  File "/home/xiejunlin/miniconda3/envs/torch/lib/python3.8/site-packages/paddle/tensor/manipulation.py", line 3543, in reshape
    out = _C_ops.reshape(x, shape)
ValueError: (InvalidArgument) The 'shape' in ReshapeOp is invalid. The input tensor X'size must be equal to the capacity of 'shape'. But received X's shape = [640, 384, 36], X's size = 8847360, 'shape' is [640, 384, 14, 14], the capacity of 'shape' is 48168960.
  [Hint: Expected capacity == in_size, but received capacity:48168960 != in_size:8847360.] (at /paddle/paddle/phi/infermeta/unary.cc:1435)



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
No stack trace in paddle, may be caused by external reasons.

----------------------
Error Message Summary:
----------------------
FatalError: `Termination signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1680688161 (unix time) try "date -d @1680688161" if you are using GNU date ***]
  [SignalInfo: *** SIGTERM (@0x3f4002bdc34) received by PID 2874713 (TID 0x7f7408b654c0) from PID 2874420 ***]

